{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29dc0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"USE_TORCH\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d90ac924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lf_utils import *\n",
    "from src.config import *\n",
    "from src.utils import get_pixels, get_label\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import enum\n",
    "import subprocess \n",
    "import pandas as pd\n",
    "\n",
    "from doctr.models import ocr_predictor\n",
    "\n",
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor\n",
    "from spear.labeling import LFSet, PreLabels\n",
    "from spear.utils import get_data, get_classes\n",
    "from spear.cage import Cage\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "imgfile =  None\n",
    "Y = None\n",
    "lf = None\n",
    "MODEL = ocr_predictor(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dfffa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pixelLabels(enum.Enum):\n",
    "    TEXT = 1\n",
    "    NOT_TEXT = 0\n",
    "\n",
    "\n",
    "class Labeling:\n",
    "    def __init__(self,imgfile, model) -> None:\n",
    "        self.imgfile = INPUT_IMG_DIR + imgfile\n",
    "        image = io.imread(self.imgfile)\n",
    "        image2 = Image.open(self.imgfile)\n",
    "        image3 = cv2.imread(self.imgfile)\n",
    "        self.CHULL        = get_convex_hull(image)\n",
    "        self.EDGES        = get_image_edges(image, WIDTH_THRESHOLD, HEIGHT_THRESHOLD, THICKNESS)\n",
    "        # self.PILLOW_EDGES = get_pillow_image_edges(image2, WIDTH_THRESHOLD, HEIGHT_THRESHOLD)\n",
    "        self.CONTOUR      = get_contour_labels(image3, WIDTH_THRESHOLD, HEIGHT_THRESHOLD, THICKNESS)\n",
    "        self.TITLE_CONTOUR = get_title_contour_labels(image3, WIDTH_THRESHOLD, HEIGHT_THRESHOLD, 7)\n",
    "        self.DOCTR        = get_doctr_labels(model, self.imgfile, image, WIDTH_THRESHOLD, HEIGHT_THRESHOLD)\n",
    "        # self.DOCTR        = get_existing_doctr_labels(ANN_DOCTR_DIR, imgfile, image, WIDTH_THRESHOLD, HEIGHT_THRESHOLD)\n",
    "        self.TESSERACT    = get_tesseract_labels(image, WIDTH_THRESHOLD, HEIGHT_THRESHOLD)\n",
    "        self.MASK_HOLES   = get_mask_holes_labels(image)\n",
    "        self.MASK_OBJECTS = get_mask_objects_labels(image, LUMINOSITY)\n",
    "        self.SEGMENTATION = get_segmentation_labels(image, WIDTH_THRESHOLD, HEIGHT_THRESHOLD, THICKNESS)\n",
    "        self.pixels = get_pixels(image)\n",
    "        self.image = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2489ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessor()\n",
    "def get_chull_info(x):\n",
    "    return lf.CHULL[x[0]][x[1]]\n",
    "\n",
    "@preprocessor()\n",
    "def get_edges_info(x):\n",
    "    return lf.EDGES[x[0]][x[1]]\n",
    "\n",
    "@preprocessor()\n",
    "def get_pillow_edges_info(x):\n",
    "    return lf.PILLOW_EDGES[x[0]][x[1]]\n",
    "\n",
    "\n",
    "@preprocessor()\n",
    "def get_doctr_info(x):\n",
    "    return lf.DOCTR[x[0]][x[1]]\n",
    "\n",
    "\n",
    "@preprocessor()\n",
    "def get_tesseract_info(x):\n",
    "    return lf.TESSERACT[x[0]][x[1]]\n",
    "\n",
    "@preprocessor()\n",
    "def get_contour_info(x):\n",
    "    return lf.CONTOUR[x[0]][x[1]]\n",
    "\n",
    "@preprocessor()\n",
    "def get_title_contour_info(x):\n",
    "    return lf.TITLE_CONTOUR[x[0]][x[1]]\n",
    "\n",
    "@preprocessor()\n",
    "def get_mask_holes_info(x):\n",
    "    return lf.MASK_HOLES[x[0]][x[1]]\n",
    "\n",
    "@preprocessor()\n",
    "def get_mask_objects_info(x):\n",
    "    return lf.MASK_OBJECTS[x[0]][x[1]]\n",
    "\n",
    "@preprocessor()\n",
    "def get_segmentation_info(x):\n",
    "    return lf.SEGMENTATION[x[0]][x[1]]\n",
    "\n",
    "\n",
    "\n",
    "@labeling_function(label = pixelLabels.NOT_TEXT, pre=[get_chull_info], name=\"CHULL_PURE\")\n",
    "def CONVEX_HULL_LABEL_PURE(pixel):\n",
    "    if(pixel):\n",
    "        return pixelLabels.NOT_TEXT\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "@labeling_function(label=pixelLabels.TEXT, pre=[get_chull_info], name=\"CHULL_NOISE\")\n",
    "def CONVEX_HULL_LABEL_NOISE(pixel):\n",
    "    if(pixel):\n",
    "        return pixelLabels.TEXT\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "\n",
    "@labeling_function(label=pixelLabels.TEXT, pre=[get_edges_info], name=\"SKIMAGE_EDGES\")\n",
    "def EDGES_LABEL(pixel):\n",
    "    if(pixel):\n",
    "        return pixelLabels.TEXT\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "@labeling_function(label = pixelLabels.NOT_TEXT, pre=[get_edges_info], name=\"SKIMAGE_EDGES_REVERSE\")\n",
    "def EDGES_LABEL_REVERSE(pixel):\n",
    "    if(pixel):\n",
    "        return ABSTAIN\n",
    "    else:\n",
    "        return pixelLabels.NOT_TEXT\n",
    "    \n",
    "    \n",
    "@labeling_function(label=pixelLabels.TEXT, pre=[get_pillow_edges_info], name=\"PILLOW_EDGES\")\n",
    "def PILLOW_EDGES_LABEL(pixel):\n",
    "    if(pixel):\n",
    "        return pixelLabels.TEXT\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(label = pixelLabels.NOT_TEXT, pre=[get_pillow_edges_info], name=\"PILLOW_EDGES_REVERSE\")\n",
    "def PILLOW_EDGES_LABEL_REVERSE(pixel):\n",
    "    if(pixel):\n",
    "        return ABSTAIN\n",
    "    else:\n",
    "        return pixelLabels.NOT_TEXT\n",
    "\n",
    "\n",
    "@labeling_function(label=pixelLabels.TEXT, pre=[get_doctr_info], name=\"DOCTR\")\n",
    "def DOCTR_LABEL(pixel):\n",
    "    if(pixel):\n",
    "        return pixelLabels.TEXT\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "@labeling_function(label=pixelLabels.TEXT, pre=[get_doctr_info], name=\"DOCTR2\")\n",
    "def DOCTR_LABEL2(pixel):\n",
    "    if(pixel):\n",
    "        return pixelLabels.TEXT\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(label=pixelLabels.TEXT, pre=[get_tesseract_info], name=\"TESSERACT\")\n",
    "def TESSERACT_LABEL(pixel):\n",
    "    if(pixel):\n",
    "        return pixelLabels.TEXT\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "@labeling_function(label=pixelLabels.TEXT, pre=[get_contour_info], name=\"CONTOUR\")\n",
    "def CONTOUR_LABEL(pixel):\n",
    "    if(pixel):\n",
    "        return pixelLabels.TEXT\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "@labeling_function(label=pixelLabels.TEXT, pre=[get_title_contour_info], name=\"CONTOUR_TITLE\")\n",
    "def CONTOUR_TITLE_LABEL(pixel):\n",
    "    if(pixel):\n",
    "        return pixelLabels.TEXT\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "@labeling_function(label=pixelLabels.NOT_TEXT, pre=[get_mask_holes_info], name=\"MASK_HOLES\")\n",
    "def MASK_HOLES_LABEL(pixel):\n",
    "    if(pixel):\n",
    "        return pixelLabels.NOT_TEXT\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "@labeling_function(label=pixelLabels.NOT_TEXT, pre=[get_mask_objects_info], name=\"MASK_OBJECTS\")\n",
    "def MASK_OBJECTS_LABEL(pixel):\n",
    "    if(pixel):\n",
    "        return pixelLabels.NOT_TEXT\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "@labeling_function(label=pixelLabels.TEXT, pre=[get_segmentation_info], name=\"SEGMENTATION\")\n",
    "def SEGMENTATION_LABEL(pixel):\n",
    "    if(pixel):\n",
    "        return pixelLabels.TEXT\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "\n",
    "### Get LF Analysis of the input images\n",
    "def analysis(img):\n",
    "\n",
    "    ### Choose the Labeling Functions which should be run\n",
    "    LFS = [ \n",
    "        CONVEX_HULL_LABEL_PURE, \n",
    "        # CONVEX_HULL_LABEL_NOISE, \n",
    "        # EDGES_LABEL, \n",
    "        # EDGES_LABEL_REVERSE, \n",
    "        # PILLOW_EDGES_LABEL, \n",
    "        # PILLOW_EDGES_LABEL_REVERSE,\n",
    "        DOCTR_LABEL,\n",
    "        # TESSERACT_LABEL,\n",
    "        CONTOUR_LABEL,\n",
    "        # MASK_HOLES_LABEL,\n",
    "        # MASK_OBJECTS_LABEL,\n",
    "        # SEGMENTATION_LABEL\n",
    "    ]\n",
    "\n",
    "    QUALITY_GUIDE = [0.85, 0.9, 0.95]\n",
    "    \n",
    "    rules = LFSet(\"DETECTION_LF\")\n",
    "    rules.add_lf_list(LFS)\n",
    "\n",
    "    R = np.zeros((lf.pixels.shape[0],len(rules.get_lfs())))\n",
    "\n",
    "    \n",
    "\n",
    "    Y = io.imread(INPUT_IMG_DIR + img)\n",
    "    name = img[:len(img) - 8]\n",
    "    df = pd.read_csv(GROUND_TRUTH_DIR+name+'_pro.txt', delimiter=' ',\n",
    "                     names=[\"token\", \"x0\", \"y0\", \"x1\", \"y1\", \"R\", \"G\", \"B\", \"font name\", \"label\"])\n",
    "\n",
    "    height, width, _ = Y.shape\n",
    "    for i in range(df.shape[0]):\n",
    "        x0, y0, x1, y1  = (df['x0'][i], df['y0'][i], df['x1'][i], df['y1'][i])\n",
    "        x0, y0, x1, y1 = (int(x0*width/1000), int(y0*height/1000), int(x1*width/1000), int(y1*height/1000))\n",
    "        w = int((x1-x0)*WIDTH_THRESHOLD)\n",
    "        h = int((y1-y0)*HEIGHT_THRESHOLD)\n",
    "        cv2.rectangle(Y, (x0, y0), (x0+w, y0+h), (0, 0, 0), cv2.FILLED)\n",
    "\n",
    "    gold_label = get_label(Y)\n",
    "\n",
    "    td_noisy_labels = PreLabels(name=\"TD\",\n",
    "                               data=lf.pixels,\n",
    "                               rules=rules,\n",
    "                               gold_labels=gold_label,\n",
    "                               labels_enum=pixelLabels,\n",
    "                               num_classes=2)\n",
    "\n",
    "    L,S = td_noisy_labels.get_labels()\n",
    "\n",
    "\n",
    "    analyse = td_noisy_labels.analyse_lfs(plot=True)\n",
    "\n",
    "    result = analyse.head(16)\n",
    "    result[\"image\"] = img\n",
    "\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "### Get CAGE based output predictions\n",
    "def cage(file, X):\n",
    "\n",
    "    ### Choose the Labeling Functions which should be run\n",
    "    LFS = [ \n",
    "        CONVEX_HULL_LABEL_PURE, \n",
    "        # CONVEX_HULL_LABEL_NOISE, \n",
    "        # EDGES_LABEL, \n",
    "        # EDGES_LABEL_REVERSE, \n",
    "        # PILLOW_EDGES_LABEL, \n",
    "        # PILLOW_EDGES_LABEL_REVERSE,\n",
    "        DOCTR_LABEL,\n",
    "        # TESSERACT_LABEL,\n",
    "        CONTOUR_LABEL,\n",
    "        # MASK_HOLES_LABEL,\n",
    "        # MASK_OBJECTS_LABEL,\n",
    "        # SEGMENTATION_LABEL\n",
    "    ]\n",
    "\n",
    "    QUALITY_GUIDE = [0.85, 0.9, 0.95]\n",
    "\n",
    "    prob_arr = np.array(QUALITY_GUIDE)\n",
    "\n",
    "    rules = LFSet(\"DETECTION_LF\")\n",
    "    rules.add_lf_list(LFS)\n",
    "\n",
    "    n_lfs = len(rules.get_lfs())\n",
    "\n",
    "    Y = io.imread(INPUT_IMG_DIR + file)\n",
    "    height, width, _ = Y.shape\n",
    "\n",
    "    if(GROUND_TRUTH_AVAILABLE):\n",
    "        if('docbank' in INPUT_DATA_DIR) or 'testing_sample' in INPUT_DATA_DIR:\n",
    "            name = file[:len(file) - 4]\n",
    "            df = pd.read_csv(GROUND_TRUTH_DIR+name+'.txt', delimiter=' ',\n",
    "                            names=[\"token\", \"x0\", \"y0\", \"x1\", \"y1\", \"R\", \"G\", \"B\", \"font name\", \"label\"])\n",
    "\n",
    "            for i in range(df.shape[0]):\n",
    "                x0, y0, x1, y1  = (df['x0'][i], df['y0'][i], df['x1'][i], df['y1'][i])\n",
    "                x0, y0, x1, y1 = (int(x0*width/1000), int(y0*height/1000), int(x1*width/1000), int(y1*height/1000))\n",
    "                w = int((x1-x0)*WIDTH_THRESHOLD)\n",
    "                h = int((y1-y0)*HEIGHT_THRESHOLD)\n",
    "                cv2.rectangle(Y, (x0, y0), (x0+w, y0+h), (0, 0, 0), cv2.FILLED)\n",
    "\n",
    "        else:\n",
    "            name = file[:len(file) - 4]\n",
    "            df = pd.read_csv(GROUND_TRUTH_DIR+name+'.txt', delimiter=' ',\n",
    "                            names=[\"label\",\"confidence\",\"x0\",\"y0\",'w','h'])   \n",
    "\n",
    "            for i in range(df.shape[0]):\n",
    "                x0, y0, w, h  = (df['x0'][i], df['y0'][i], df['w'][i], df['h'][i])\n",
    "                w = int(w*WIDTH_THRESHOLD)\n",
    "                h = int(h*HEIGHT_THRESHOLD)\n",
    "                cv2.rectangle(Y, (x0, y0), (x0+w, y0+h), (0, 0, 0), cv2.FILLED)\n",
    "\n",
    "    \n",
    "    gold_label = get_label(Y)\n",
    "\n",
    "\n",
    "    path_json = 'sms_json.json'\n",
    "    T_path_pkl = 'pickle_T.pkl' #test data - have true labels\n",
    "    U_path_pkl = 'pickle_U.pkl' #unlabelled data - don't have true labels\n",
    "\n",
    "    log_path_cage_1 = 'sms_log_1.txt' #cage is an algorithm, can be found below\n",
    "\n",
    "\n",
    "    sms_noisy_labels = PreLabels(name=\"sms\",\n",
    "                               data=X,\n",
    "                               gold_labels=gold_label,\n",
    "                               rules=rules,\n",
    "                               labels_enum=pixelLabels,\n",
    "                               num_classes=2)\n",
    "    sms_noisy_labels.generate_pickle(T_path_pkl)\n",
    "    sms_noisy_labels.generate_json(path_json) #generating json files once is enough\n",
    "\n",
    "    sms_noisy_labels = PreLabels(name=\"sms\",\n",
    "                                data=X,\n",
    "                                rules=rules,\n",
    "                                labels_enum=pixelLabels,\n",
    "                                num_classes=2) #note that we don't pass gold_labels here, for the unlabelled data\n",
    "    sms_noisy_labels.generate_pickle(U_path_pkl)\n",
    "\n",
    "\n",
    "    cage = Cage(path_json = path_json, n_lfs = n_lfs)\n",
    "\n",
    "    probs = cage.fit_and_predict_proba(path_pkl = U_path_pkl, path_test = T_path_pkl, path_log = log_path_cage_1, \\\n",
    "                                    qt = prob_arr, qc = prob_arr, metric_avg = ['binary'], n_epochs = 50, lr = 0.01)\n",
    "    labels = np.argmax(probs, 1)\n",
    "    x,y,_ = Y.shape\n",
    "\n",
    "    labels = labels.reshape(x,y)\n",
    "    io.imsave(RESULTS_DIR + file, labels)\n",
    "\n",
    "\n",
    "### Postprocessing Step\n",
    "def get_bboxes(file):\n",
    "\n",
    "    img = cv2.imread(RESULTS_DIR + file)\n",
    "\n",
    "    img = invert(img)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Convert the grayscale image to binary\n",
    "    ret, binary = cv2.threshold(gray, 100, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "    # To detect object contours, we want a black background and a white foreground, so we invert the image (i.e. 255 - pixel value)\n",
    "    inverted_binary = ~binary\n",
    "\n",
    "    # Find the contours on the inverted binary image, and store them in a list\n",
    "    # Contours are drawn around white blobs. hierarchy variable contains info on the relationship between the contours\n",
    "    contours, hierarchy = cv2.findContours(inverted_binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    bboxes = []\n",
    "    # Draw a bounding box around all contours\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        w = int(w*(1/WIDTH_THRESHOLD))\n",
    "        h = int(h*(1/HEIGHT_THRESHOLD))\n",
    "        # Make sure contour area is large enough\n",
    "        if cv2.contourArea(c) > 30:\n",
    "            bboxes.append(['text',1,x, y, w, h])\n",
    "\n",
    "    final_img = cv2.imread(INPUT_IMG_DIR + file)\n",
    "    for b in bboxes:\n",
    "        x = b[2]\n",
    "        y = b[3]\n",
    "        w = int(b[4])\n",
    "        h = int(b[5])\n",
    "        cv2.rectangle(final_img,(x,y), (x+w,y+h), (0, 255, 0),1)\n",
    "\n",
    "    df = pd.DataFrame(bboxes, columns = ['label', 'confidence', 'X', 'Y', 'W', 'H'])\n",
    "    name = file[:len(file) - 4]\n",
    "    io.imsave(PREDICTIONS_DIR + name + '_pred.jpg', final_img)\n",
    "    df.to_csv(OUT_TXT_DIR + name + '.txt', sep=' ',index=False, header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be98aa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                   | 0/100 [00:09<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Labeling object at 0x7fdfd2bc5250>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Main Code\n",
    "if __name__ == \"__main__\":\n",
    "    dir_list = os.listdir(INPUT_IMG_DIR)\n",
    "\n",
    "    ### CAGE Execution\n",
    "    for img_file in tqdm(dir_list):\n",
    "        # if not (os.path.exists(RESULTS_DIR + img_file)):\n",
    "        lf = Labeling(imgfile=img_file, model=MODEL)\n",
    "        print(lf)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8803b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lf.pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9447241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(os.path.exists('features.pkl')):\n",
    "    with open('features.pkl', 'rb') as f:\n",
    "        X_feats = pickle.load(f)\n",
    "else:\n",
    "    X_feats = np.random.uniform(-1, 1, size=(X.shape[0], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b4cd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3740000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b29d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = io.imread(INPUT_IMG_DIR + img_file)\n",
    "height, width, _ = Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5dd6617",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(GROUND_TRUTH_AVAILABLE):\n",
    "    if('docbank' in INPUT_DATA_DIR) or 'testing_sample' in INPUT_DATA_DIR:\n",
    "        name = img_file[:len(img_file) - 4]\n",
    "        df = pd.read_csv(GROUND_TRUTH_DIR+name+'.txt', delimiter=' ',\n",
    "                        names=[\"token\", \"x0\", \"y0\", \"x1\", \"y1\", \"R\", \"G\", \"B\", \"font name\", \"label\"])\n",
    "\n",
    "        for i in range(df.shape[0]):\n",
    "            x0, y0, x1, y1  = (df['x0'][i], df['y0'][i], df['x1'][i], df['y1'][i])\n",
    "            x0, y0, x1, y1 = (int(x0*width/1000), int(y0*height/1000), int(x1*width/1000), int(y1*height/1000))\n",
    "            w = int((x1-x0)*WIDTH_THRESHOLD)\n",
    "            h = int((y1-y0)*HEIGHT_THRESHOLD)\n",
    "            cv2.rectangle(Y, (x0, y0), (x0+w, y0+h), (0, 0, 0), cv2.FILLED)\n",
    "\n",
    "    else:\n",
    "        name = file[:len(file) - 4]\n",
    "        df = pd.read_csv(GROUND_TRUTH_DIR+name+'.txt', delimiter=' ',\n",
    "                        names=[\"label\",\"confidence\",\"x0\",\"y0\",'w','h'])   \n",
    "\n",
    "        for i in range(df.shape[0]):\n",
    "            x0, y0, w, h  = (df['x0'][i], df['y0'][i], df['w'][i], df['h'][i])\n",
    "            w = int(w*WIDTH_THRESHOLD)\n",
    "            h = int(h*HEIGHT_THRESHOLD)\n",
    "            cv2.rectangle(Y, (x0, y0), (x0+w, y0+h), (0, 0, 0), cv2.FILLED)\n",
    "\n",
    "\n",
    "Y = get_label(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac58322",
   "metadata": {},
   "outputs": [],
   "source": [
    "LFS = [ \n",
    "    CONVEX_HULL_LABEL_PURE, \n",
    "    # CONVEX_HULL_LABEL_NOISE, \n",
    "    # EDGES_LABEL, \n",
    "    # EDGES_LABEL_REVERSE, \n",
    "    # PILLOW_EDGES_LABEL, \n",
    "    # PILLOW_EDGES_LABEL_REVERSE,\n",
    "    DOCTR_LABEL,\n",
    "    # TESSERACT_LABEL,\n",
    "    CONTOUR_LABEL,\n",
    "    # MASK_HOLES_LABEL,\n",
    "    # MASK_OBJECTS_LABEL,\n",
    "    # SEGMENTATION_LABEL\n",
    "]\n",
    "\n",
    "rules = LFSet(\"DETECTION_LF\")\n",
    "rules.add_lf_list(LFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "622cd9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3740000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40bcbe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_various_data(X, Y, X_feats, temp_len, validation_size = 100, test_size = 200, L_size = 100, U_size = None):\n",
    "    if U_size == None:\n",
    "        U_size = X.shape[0] - L_size - validation_size - test_size\n",
    "        print(U_size)\n",
    "    index = np.arange(X[0].size)\n",
    "    index = np.random.permutation(index)\n",
    "    X = X[index]\n",
    "    Y = Y[index]\n",
    "    X_feats = X_feats[index]\n",
    "\n",
    "    X_V = X[-validation_size:]\n",
    "    Y_V = Y[-validation_size:]\n",
    "    X_feats_V = X_feats[-validation_size:]\n",
    "    R_V = np.zeros((validation_size, temp_len))\n",
    "\n",
    "    X_T = X[-(validation_size+test_size):-validation_size]\n",
    "    Y_T = Y[-(validation_size+test_size):-validation_size]\n",
    "    X_feats_T = X_feats[-(validation_size+test_size):-validation_size]\n",
    "    R_T = np.zeros((test_size,temp_len))\n",
    "\n",
    "    X_L = X[-(validation_size+test_size+L_size):-(validation_size+test_size)]\n",
    "    Y_L = Y[-(validation_size+test_size+L_size):-(validation_size+test_size)]\n",
    "    X_feats_L = X_feats[-(validation_size+test_size+L_size):-(validation_size+test_size)]\n",
    "    R_L = np.zeros((L_size,temp_len))\n",
    "\n",
    "    # X_U = X[:-(validation_size+test_size+L_size)]\n",
    "    X_U = X[:U_size]\n",
    "    X_feats_U = X_feats[:U_size]\n",
    "    # Y_U = Y[:-(validation_size+test_size+L_size)]\n",
    "    R_U = np.zeros((U_size,temp_len))\n",
    "\n",
    "    return X_V,Y_V,X_feats_V,R_V, X_T,Y_T,X_feats_T,R_T, X_L,Y_L,X_feats_L,R_L, X_U,X_feats_U,R_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a641f2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3739400\n"
     ]
    }
   ],
   "source": [
    "# from spear.spear.helper.utils import load_data_to_numpy, get_various_data\n",
    "\n",
    "validation_size = 100\n",
    "test_size = 400\n",
    "L_size = 100\n",
    "U_size = None\n",
    "n_lfs = len(rules.get_lfs())\n",
    "\n",
    "X_V, Y_V, X_feats_V,_, X_T, Y_T, X_feats_T,_, X_L, Y_L, X_feats_L,_, X_U, X_feats_U,_ = get_various_data(X, Y,\\\n",
    "    X_feats, n_lfs, validation_size, test_size, L_size, U_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f37236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_json = 'data_pipeline/JL/sms_json.json'\n",
    "V_path_pkl = 'data_pipeline/JL/sms_pickle_V.pkl' #validation data - have true labels\n",
    "T_path_pkl = 'data_pipeline/JL/sms_pickle_T.pkl' #test data - have true labels\n",
    "L_path_pkl = 'data_pipeline/JL/sms_pickle_L.pkl' #Labeled data - have true labels\n",
    "U_path_pkl = 'data_pipeline/JL/sms_pickle_U.pkl' #unlabelled data - don't have true labels\n",
    "\n",
    "log_path_jl_1 = 'log/JL/sms_log_1.txt' #jl is an algorithm, can be found below\n",
    "params_path = 'params/JL/sms_params.pkl' #file path to store parameters of JL, used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7eb7bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 8004.40it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 7194.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# from spear.labeling import PreLabels\n",
    "\n",
    "sms_noisy_labels = PreLabels(name=\"sms\",\n",
    "                               data=X_V,\n",
    "                               gold_labels=Y_V,\n",
    "                               data_feats=X_feats_V,\n",
    "                               rules=rules,\n",
    "                               labels_enum=pixelLabels,\n",
    "                               num_classes=2)\n",
    "sms_noisy_labels.generate_pickle(V_path_pkl)\n",
    "sms_noisy_labels.generate_json(path_json) #generating json files once is enough\n",
    "\n",
    "sms_noisy_labels = PreLabels(name=\"sms\",\n",
    "                               data=X_T,\n",
    "                               gold_labels=Y_T,\n",
    "                               data_feats=X_feats_T,\n",
    "                               rules=rules,\n",
    "                               labels_enum=pixelLabels,\n",
    "                               num_classes=2)\n",
    "sms_noisy_labels.generate_pickle(T_path_pkl)\n",
    "\n",
    "sms_noisy_labels = PreLabels(name=\"sms\",\n",
    "                               data=X_L,\n",
    "                               gold_labels=Y_L,\n",
    "                               data_feats=X_feats_L,\n",
    "                               rules=rules,\n",
    "                               labels_enum=pixelLabels,\n",
    "                               num_classes=2)\n",
    "sms_noisy_labels.generate_pickle(L_path_pkl)\n",
    "\n",
    "sms_noisy_labels = PreLabels(name=\"sms\",\n",
    "                               data=X_U,\n",
    "                               rules=rules,\n",
    "                               data_feats=X_feats_U,\n",
    "                               labels_enum=pixelLabels,\n",
    "                               num_classes=2) #note that we don't pass gold_labels here, for the unlabelled data\n",
    "sms_noisy_labels.generate_pickle(U_path_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8715e427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████████████▏                                                                                                  | 19/100 [00:01<00:06, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stopping at epoch: 19\tbest_epoch: 8\n",
      "score used: f1_score\n",
      "best_gm_val_score:1.0\tbest_fm_val_score:1.0\n",
      "best_gm_test_score:0.0\tbest_fm_test_score:0.0\n",
      "best_gm_test_precision:0.0\tbest_fm_test_precision:0.0\n",
      "best_gm_test_recall:0.0\tbest_fm_test_recall:0.0\n",
      "probs_fm shape:  (2, 2)\n",
      "probs_gm shape:  (2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from spear.jl import JL\n",
    "\n",
    "loss_func_mask = [1,1,1,1,1,1,1] \n",
    "'''\n",
    "One can keep 0s in places where he don't want the specific loss function to be part\n",
    "the final loss function used in training. Refer documentation(spear.JL.core.JL) to understand\n",
    "the which index of loss_func_mask refers to what loss function.\n",
    "\n",
    "Note: the loss_func_mask above may not be the optimal mask for sms dataset. We have to try\n",
    "      some other masks too, to find the best one that gives good accuracies.\n",
    "'''\n",
    "batch_size = 150\n",
    "lr_fm = 0.0005\n",
    "lr_gm = 0.01\n",
    "use_accuracy_score = False\n",
    "\n",
    "n_features = 10\n",
    "n_hidden = 512\n",
    "feature_model = 'nn'\n",
    "\n",
    "jl = JL(path_json = path_json, n_lfs = n_lfs, n_features = n_features, feature_model = feature_model, \\\n",
    "        n_hidden = n_hidden)\n",
    "\n",
    "probs_fm, probs_gm = jl.fit_and_predict_proba(path_L = L_path_pkl, path_U = U_path_pkl, path_V = V_path_pkl, \\\n",
    "        path_T = T_path_pkl, loss_func_mask = loss_func_mask, batch_size = batch_size, lr_fm = lr_fm, lr_gm = \\\n",
    "    lr_gm, use_accuracy_score = use_accuracy_score, path_log = log_path_jl_1, return_gm = True, n_epochs = \\\n",
    "    100, start_len = 7,stop_len = 10, is_qt = True, is_qc = True, qt = 0.9, qc = 0.85, metric_avg = 'binary')\n",
    "\n",
    "labels = np.argmax(probs_fm, 1)\n",
    "print(\"probs_fm shape: \", probs_fm.shape)\n",
    "print(\"probs_gm shape: \", probs_gm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2a001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41fb1282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b580e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 0]] [1 1] [[ 0.8193134  -0.08454541  0.68251242 -0.58919287 -0.08171706 -0.79555823\n",
      "   0.5203266  -0.58709283  0.52584287  0.18382199]\n",
      " [-0.88036951  0.05692124 -0.33260052 -0.0986374   0.11351927 -0.16085525\n",
      "   0.64087395  0.07896821  0.0099363  -0.24313517]] [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]] [] [] [] [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]] [] [] [] [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]] [[0 1]\n",
      " [0 0]] [[ 0.8193134  -0.08454541  0.68251242 -0.58919287 -0.08171706 -0.79555823\n",
      "   0.5203266  -0.58709283  0.52584287  0.18382199]\n",
      " [-0.88036951  0.05692124 -0.33260052 -0.0986374   0.11351927 -0.16085525\n",
      "   0.64087395  0.07896821  0.0099363  -0.24313517]] [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_V, Y_V, X_feats_V,_, X_T, Y_T, X_feats_T,_, X_L, Y_L, X_feats_L,_, X_U, X_feats_U,_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4be201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
