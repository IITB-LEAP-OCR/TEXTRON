{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpNrdGDINJKD"
      },
      "source": [
        "# Maths Detection Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDs5Xo4xxpis",
        "outputId": "3ecd6acd-134c-4a6f-d259-9adbcbf7a6b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-10-25 02:39:07--  https://sharelatex-wiki-cdn-671420.c.cdn77.org/learn-scripts/images/f/fe/Amsexample.png\n",
            "Resolving sharelatex-wiki-cdn-671420.c.cdn77.org (sharelatex-wiki-cdn-671420.c.cdn77.org)... 185.76.10.3, 185.76.10.12, 185.59.222.21, ...\n",
            "Connecting to sharelatex-wiki-cdn-671420.c.cdn77.org (sharelatex-wiki-cdn-671420.c.cdn77.org)|185.76.10.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88919 (87K) [image/png]\n",
            "Saving to: ‘Amsexample.png’\n",
            "\n",
            "\rAmsexample.png        0%[                    ]       0  --.-KB/s               \rAmsexample.png      100%[===================>]  86.83K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-10-25 02:39:07 (5.29 MB/s) - ‘Amsexample.png’ saved [88919/88919]\n",
            "\n",
            "\u001b[K     |████████████████████████████████| 676.9 MB 3.9 kB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 52.1 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.1.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.1.0 which is incompatible.\n",
            "fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.1.0 which is incompatible.\n",
            "fastai 2.7.9 requires torchvision>=0.8.2, but you have torchvision 0.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hDownloading...\n",
            "From: https://drive.google.com/uc?id=1bGNvg9uLCTbVE9hk1yWE-2tLgX1eg_me\n",
            "To: /content/AMATH512_e1GTDB.pth\n",
            "100% 96.6M/96.6M [00:01<00:00, 81.0MB/s]\n",
            "Cloning into 'ScanSSD'...\n",
            "remote: Enumerating objects: 2933, done.\u001b[K\n",
            "remote: Total 2933 (delta 0), reused 0 (delta 0), pack-reused 2933\u001b[K\n",
            "Receiving objects: 100% (2933/2933), 306.05 MiB | 25.48 MiB/s, done.\n",
            "Resolving deltas: 100% (1306/1306), done.\n"
          ]
        }
      ],
      "source": [
        "# # Get the sample image for showcasing \n",
        "# !wget https://sharelatex-wiki-cdn-671420.c.cdn77.org/learn-scripts/images/f/fe/Amsexample.png\n",
        "\n",
        "# Install old version of the packages (this might take a while)\n",
        "!pip install torch==1.1.0 torchvision==0.3.0 -q\n",
        "\n",
        "# Download the pre trained model by MaliParag from his Google Drive link\n",
        "!gdown 1bGNvg9uLCTbVE9hk1yWE-2tLgX1eg_me\n",
        "\n",
        "# Clone repo from Github\n",
        "!git clone https://github.com/MaliParag/ScanSSD.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZPcNEzQyObs"
      },
      "outputs": [],
      "source": [
        "# Brute force restart of the Kernel\n",
        "import os\n",
        "os._exit(00)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCW9pAuv0tkL"
      },
      "outputs": [],
      "source": [
        "# Fix relative import issues\n",
        "import sys, os\n",
        "sys.path.insert(0, os.path.join('/content', 'ScanSSD'))\n",
        "sys.path.insert(0, os.path.join('/content', 'ScanSSD', 'layers'))\n",
        "sys.path.insert(0, os.path.join('/content', 'ScanSSD', 'gtdb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kao1jxUOLRq2"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from ScanSSD.ssd import build_ssd\n",
        "from ScanSSD.data import config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hxccLSa8kaX"
      },
      "outputs": [],
      "source": [
        "# For viewing images in Colab (You must remove if running this locally)\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwNTzUjcLoEl"
      },
      "outputs": [],
      "source": [
        "class ArgStub():\n",
        "    def __init__ (self):\n",
        "        self.cuda = False\n",
        "        self.kernel = (1, 5)\n",
        "        self.padding = (0, 2)\n",
        "        self.phase = 'test'\n",
        "        self.visual_threshold = 0.6\n",
        "        self.verbose = False\n",
        "        self.exp_name = 'SSD'\n",
        "        self.model_type = 512\n",
        "        self.use_char_info = False\n",
        "        self.limit = -1\n",
        "        self.cfg = 'hboxes512'\n",
        "        self.batch_size = 4\n",
        "        self.num_workers = 2\n",
        "        self.neg_mining = True\n",
        "        self.log_dir = 'logs'\n",
        "        self.stride = 0.1\n",
        "        self.window = 1200\n",
        "\n",
        "\n",
        "def draw_box (image, boxes):\n",
        "    for b in boxes:\n",
        "        cv2.rectangle(image, (b[0], b[1]), (b[2], b[3]), (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "def _img_to_tensor (image):\n",
        "    rimg = cv2.resize(image, (512, 512),\n",
        "                      interpolation = cv2.INTER_AREA).astype(np.float32)\n",
        "    rimg -= np.array((246, 246, 246), dtype=np.float32)\n",
        "    rimg = rimg[:, :, (2, 1, 0)]\n",
        "    return torch.from_numpy(rimg).permute(2, 0, 1)\n",
        "\n",
        "\n",
        "def FixImgCoordinates (images, boxes):\n",
        "    new_boxes = []\n",
        "    if isinstance(images, list):\n",
        "            for i in range(len(images)):\n",
        "                print(images[i].shape)\n",
        "                bbs = []\n",
        "                for o_box in boxes[i] :\n",
        "                    b = [None] * 4\n",
        "                    b[0] = int(o_box[0] * images[i].shape[0])\n",
        "                    b[1] = int(o_box[1] * images[i].shape[1])\n",
        "                    b[2] = int(o_box[2] * images[i].shape[0])\n",
        "                    b[3] = int(o_box[3] * images[i].shape[1])\n",
        "                    bbs.append(b)\n",
        "\n",
        "                new_boxes.append(bbs)\n",
        "    else:\n",
        "        bbs = []\n",
        "        for o_box in boxes[0] :\n",
        "            b = [None] * 4\n",
        "            b[0] = int(o_box[0] * images.shape[0])\n",
        "            b[1] = int(o_box[1] * images.shape[1])\n",
        "            b[2] = int(o_box[2] * images.shape[0])\n",
        "            b[3] = int(o_box[3] * images.shape[1])\n",
        "            bbs.append(b)\n",
        "\n",
        "            # this could be\n",
        "            # b[0] = int(o_box[0] * images.shape[0]) ==> b[0] = int(o_box[0] * images.shape[1])\n",
        "            # b[1] = int(o_box[1] * images.shape[1]) ==> b[1] = int(o_box[1] * images.shape[0])\n",
        "            # b[2] = int(o_box[2] * images.shape[0]) ==> b[2] = int(o_box[2] * images.shape[1])\n",
        "            # b[3] = int(o_box[3] * images.shape[1]) ==> b[3] = int(o_box[3] * images.shape[0])\n",
        "\n",
        "        new_boxes.append(bbs)\n",
        "\n",
        "    return new_boxes\n",
        "\n",
        "\n",
        "def DrawAllBoxes(images, boxes):\n",
        "    for i in range(len(images)):\n",
        "        draw_box(images[i], boxes[i])\n",
        "\n",
        "class MathDetector():\n",
        "\n",
        "    def __init__(self, weight_path, args):\n",
        "        net = build_ssd(args, 'test', config.exp_cfg[args.cfg], 0, args.model_type, 2)\n",
        "        self._net = net # nn.DataParallel(net)\n",
        "        weights = torch.load(weight_path, map_location = torch.device('cpu'))\n",
        "\n",
        "        new_weights = OrderedDict()\n",
        "        for k, v in weights.items():\n",
        "            name = k[7:] # remove `module.`\n",
        "            new_weights[name] = v\n",
        "\n",
        "        self._net.load_state_dict(new_weights)\n",
        "        self._net.eval()\n",
        "\n",
        "    def Detect (self, thres, images):\n",
        "\n",
        "        cls = 1                 # math class\n",
        "        boxes = []\n",
        "        scores = []\n",
        "\n",
        "        y, debug_boxes, debug_scores = self._net(images)  # forward pass\n",
        "\n",
        "        detections = y.data\n",
        "\n",
        "        for k in range(len(images)):\n",
        "\n",
        "            img_boxes = []\n",
        "            img_scores = []\n",
        "            for j in range(detections.size(2)):\n",
        "\n",
        "                if ( detections[k, cls, j, 0] < thres ):\n",
        "                    continue\n",
        "\n",
        "                pt = detections[k, cls, j, 1:]\n",
        "                coords = (pt[0], pt[1], pt[2], pt[3])\n",
        "                img_boxes.append(coords)\n",
        "                img_scores.append(detections[k, cls, j, 0])\n",
        "\n",
        "            boxes.append(img_boxes)\n",
        "            scores.append(img_scores)\n",
        "\n",
        "        return boxes, scores\n",
        "\n",
        "    def ShowNetwork (self):\n",
        "        print(self._net)\n",
        "\n",
        "    def DetectAny (self, thres, image):\n",
        "        if isinstance(image, list):\n",
        "            t_list = [_img_to_tensor(img) for img in image]\n",
        "            t = torch.stack(t_list, dim = 0)\n",
        "        else:\n",
        "            t = _img_to_tensor(image).unsqueeze(0)\n",
        "        # fix box coordinates to image pixel coordinates\n",
        "        boxes, scores = self.Detect(thres, t)\n",
        "        return FixImgCoordinates(image, boxes), scores\n",
        "\n",
        "md = MathDetector('AMATH512_e1GTDB.pth', ArgStub())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUD7xkwU8HM4"
      },
      "outputs": [],
      "source": [
        "# Load image for detection\n",
        "img = cv2.imread('/content/maths_tets_page-0002.jpg', cv2.IMREAD_COLOR)\n",
        "\n",
        "# Container for detection results\n",
        "borders = []\n",
        "\n",
        "# Fill smaller images with 0s\n",
        "image_height, image_width, channels = img.shape\n",
        "\n",
        "# Compute the number of rolling windows\n",
        "nwindows_vertical = math.ceil(image_height / 512)\n",
        "nwindows_horizontal = math.ceil(image_width / 512)\n",
        "\n",
        "# Use a rolling window of 515px for detection\n",
        "for i in range(nwindows_vertical):\n",
        "  for j in range(nwindows_horizontal):\n",
        "\n",
        "    window_x_start = min(512*j, image_width)\n",
        "    window_x_end = min(window_x_start+512, image_width)\n",
        "    window_y_start = min(512*i, image_height)*i\n",
        "    window_y_end = min(window_y_start+512, image_height)\n",
        "    window_width = window_x_end-window_x_start\n",
        "    window_height = window_y_end-window_y_start\n",
        "\n",
        "    rolling_window = img[window_y_start:window_y_end, window_x_start:window_x_end]\n",
        "\n",
        "    # create new image of desired size with white background\n",
        "    new_image_width = 512\n",
        "    new_image_height = 512\n",
        "    color = (255,255,255)\n",
        "    padded_window = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n",
        "    # compute center offset\n",
        "    x_center = (new_image_width - window_width) // 2\n",
        "    y_center = (new_image_height - window_height) // 2\n",
        "\n",
        "    # Copy the window to the center of the white square\n",
        "    padded_window[y_center:y_center+window_height, x_center:x_center+window_width] = rolling_window\n",
        "\n",
        "    # Detect math elements\n",
        "    window_borders, scores = md.DetectAny(0.33, padded_window)\n",
        "    \n",
        "    # Fix borders to the whole image, not just the window\n",
        "    for k in range(len(window_borders[0])): \n",
        "      window_borders[0][k][0] = window_x_start+(window_borders[0][k][0]-(new_image_width-window_width)//2)\n",
        "      window_borders[0][k][1] = window_y_start+(window_borders[0][k][1]-(new_image_height-window_height)//2)\n",
        "      window_borders[0][k][2] = window_x_start+(window_borders[0][k][2]-(new_image_width-window_width)//2)\n",
        "      window_borders[0][k][3] = window_y_start+(window_borders[0][k][3]-(new_image_height-window_height)//2) \n",
        "    borders = borders + window_borders[0]\n",
        "  \n",
        "# Do not delete this \n",
        "borders = [borders]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpAorOg4g3lg"
      },
      "outputs": [],
      "source": [
        "display(borders)\n",
        "img_c = np.copy(img)\n",
        "DrawAllBoxes([img_c], borders)\n",
        "\n",
        "cv2_imshow(img_c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUwhMmjyB0ER"
      },
      "outputs": [],
      "source": [
        "boxes = [\n",
        "  [412, 454, 511, 510],\n",
        "  [236, 261, 519, 322],\n",
        "  [367, 187, 510, 235],\n",
        "  [431, 333, 510, 387],\n",
        "  [504, 178, 825, 244],\n",
        "  [636, 447, 787, 507],\n",
        "  [514, 450, 604, 507],\n",
        "  [510, 266, 962, 318],\n",
        "  [510, 332, 760, 396],\n",
        "  [389, 695, 510, 730],\n",
        "  [219, 834, 508, 895],\n",
        "  [194, 968, 218, 996],\n",
        "  [477, 625, 512, 663],\n",
        "  [363, 531, 510, 557],\n",
        "  [261, 529, 301, 551],\n",
        "  [226, 538, 309, 554],\n",
        "  [514, 834, 971, 897],\n",
        "  [515, 681, 799, 743],\n",
        "  [508, 627, 720, 661],\n",
        "  [512, 913, 740, 949],\n",
        "  [810, 763, 873, 791]\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krhFqWBCC972"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('/content/maths_tets_page-0007.jpg', cv2.IMREAD_COLOR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4migumXgDMOv"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def crop(image_path, coords, saved_location):\n",
        "    image_obj = Image.open(image_path)\n",
        "    cropped_image = image_obj.crop(coords)\n",
        "    cropped_image.save(saved_location)\n",
        "    cropped_image.show()\n",
        "\n",
        "image = \"/content/maths_tets_page-0007.jpg\"\n",
        "idx = 0\n",
        "for box in boxes:\n",
        "  box = tuple(box)\n",
        "  crop(image, box, f'/content/cropped/cropped_{idx}_.jpg')\n",
        "  idx = idx + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWGDCEbREzGf"
      },
      "outputs": [],
      "source": [
        "!zip -r cropped.zip /content/cropped/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhK8ib6ZgrWL"
      },
      "source": [
        "# Maths Recognition "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaEQWHLif9mX",
        "outputId": "bc525812-ac05-46ed-bb8b-923b3a45b275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 560 kB 30.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 431 kB 62.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 41 kB 540 kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 59.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 58.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 60.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 72.2 MB/s \n",
            "\u001b[?25h  Building wheel for entmax (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pix2tex -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPzovuh4hR0y",
        "outputId": "4e0fe1b9-c1b4-4cec-ec75-18d6bb036a74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: Pillow 9.3.0\n",
            "Uninstalling Pillow-9.3.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/PIL/*\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow-9.3.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libXau-00ec42fe.so.6.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libbrotlicommon-cf2297e4.so.1.0.9\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libbrotlidec-97e69943.so.1.0.9\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libfreetype-7d9be1ab.so.6.18.3\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libharfbuzz-5e08a948.so.0.50301.0\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libjpeg-b1f3a3b7.so.62.3.0\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/liblcms2-1e643a89.so.2.0.13\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/liblzma-816f5b19.so.5.2.7\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libopenjp2-fca9bf24.so.2.5.0\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libpng16-a57c74e2.so.16.38.0\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libtiff-3a0dc242.so.5.8.0\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libwebp-b246aa5a.so.7.1.5\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libwebpdemux-ac83b303.so.2.0.11\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libwebpmux-502c7428.so.3.0.10\n",
            "    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libxcb-421a6fdb.so.1.1.0\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled Pillow-9.3.0\n"
          ]
        }
      ],
      "source": [
        "#if after restart kernal the bellow function doesnt work\n",
        "!pip uninstall Pillow\n",
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpPtOtv-BudL",
        "outputId": "42d76588-0888-49ad-81f4-60e2e566ceb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "download weights v0.0.1 to path /usr/local/lib/python3.7/dist-packages/pix2tex/model/checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "weights.pth: 100%|██████████| 97.4M/97.4M [00:12<00:00, 8.22Mb/s]\n",
            "image_resizer.pth: 100%|██████████| 18.5M/18.5M [00:05<00:00, 3.88Mb/s]\n"
          ]
        }
      ],
      "source": [
        "from pix2tex.cli import LatexOCR\n",
        "from PIL import Image\n",
        "\n",
        "LatexModel = LatexOCR()\n",
        "def forumla_detection(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    return LatexModel(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MGmdKqj2hnR9",
        "outputId": "4ba91403-ce49-4e01-e551-9b271c3262d2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a x^{a}+\\\\mathbf{bx}+c=0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forumla_detection(\"/content/Screenshot 2022-11-18 at 5.07.25 PM.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQUmXmIeGQyV",
        "outputId": "673ba286-4db8-43c1-ae25-b2ff2397b563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cropped_12_.jpg  -  \\mathbf{M}{\\big\\{}\n",
            "cropped_5_.jpg  -  \\Omega_{q}={\\frac{\\pi^{2}}{6}}-\\sum_{r=1}^{q}{\\frac{1}{r^{2}}}.\n",
            "cropped_10_.jpg  -  {\\bf\\tau}_{(001)T,t}^{(00i_{1})q}=\\frac{(T-t)^{5/2}}{2}\\biggl(\\frac{1}{3}\\zeta_{0}^{(i_{1})}+\\frac{1}{\\sqrt{2}\\pi^{i}}\n",
            "cropped_2_.jpg  -  J_{(0|)T,t}^{(0|\\l_{i})q}=\\frac{(T-t)}{2}\n",
            "cropped_15_.jpg  -  {\\mathfrak{I}}_{r}^{\\gamma}\\,,\\;\\;\\{{\\mathfrak{I}}_{r-1}^{\\gamma},\n",
            "cropped_4_.jpg  -  \\stackrel{\\bar{3}}{\\longrightarrow}\\left(\\begin{array}{l l}{{\\zeta^{\\left(i_{1}\\right)}}}&{{\\sqrt{2}}}\\\\ {{\\zeta^{\\left(i_{0}\\right)}}}&{{\\strut}}\\\\ {{\\strut\\sim}}&{{\\.T}}\\end{array}\\left(\\stackrel{\\left[i_{1}\\right]}{\\left.\\sum_{T=1}^{\\left(i_{1}\\right)}+\\sqrt{\\Omega_{q}\\right.}\\zeta^{\\left(i_{1}\\right)}}\\end{array}\\right)\\right)\n",
            "cropped_13_.jpg  -  {\\frac{z^{(l)}}{s q}}\\ (r=1,\\ldots,\\,q;\n",
            "cropped_7_.jpg  -  \\begin{array}{l}{{\\begin{array}{c}{{q}}\\\\ {{\\sum_{-}\\left(\\langle\\stackrel{\\prime}{}_{1}\\rangle\\langle\\langle i_{1}\\rangle}{}(i_{1}\\rangle}}\\\\ {{\\sum_{-}\\left(\\stackrel{\\prime}{}_{-}\\rangle\\Im_{T}\\cdot\\Im_{T-}!}}\\end{array}-\\stackrel{\\langle i_{1}\\rangle}{\\sim}\\right.\\langle i_{2}\\rangle\\quad\\langle i_{2}\\rangle\\quad\\left.-\\langle\\stackrel{\\langle i_{i}\\rangle}{\\mathfrak{M}\\rangle}\\right.\\left.-\\stackrel{\\prime}{\\langle i_{i}\\rangle}\\right.\n",
            "cropped_17_.jpg  -  \\begin{array}{c}{{f^{(i_{1}i_{2})q}}}\\end{array}\\biggr)={\\frac{(T-t)^{2}}{2\\pi^{2}}}\\biggl({\\frac{\\pi^{2}}{6}}-\\sum_{r=1}^{q}{\\frac{1}{r^{2}}},\n",
            "cropped_18_.jpg  -  (J_{(0|I,I}^{(b_{i})}-J_{(0|I)I,I}^{(b_{i})q})^{2}\\}=0,\n",
            "cropped_20_.jpg  -  J_{(0,1)/7,t}^{(0,0_{i})q}\n",
            "cropped_14_.jpg  -  {\\zeta_{\\cdot,\\nu}^{(i)}}_{\\nu}^{\\phantom{)}}_{\\nu}\n",
            "cropped_9_.jpg  -  \\mathrm{M}\\left\\{(J_{(11)T,t}^{(i i_{1})}-.\n",
            "cropped_6_.jpg  -  \\sum_{i=q+1}^{\\infty}{\\frac{1}{1}}\\zeta_{2r-1}^{(i)}\n",
            "cropped_16_.jpg  -  \\left(\\sum_{r=1}^{q}\\frac{1}{r^{2}}\\zeta_{2r}^{(i_{i})}+\\sqrt{\\beta_{q}}\\Pi_{q}^{(i_{i})}\\right)+\\frac{1}{\\sqrt{2}\\pi}\\left(\\sum_{r=1}^{q}\\frac{1}{r}\\zeta_{2r-1}^{(i_{i})}+\\sqrt{\\Omega_{q}}\\zeta_{q}^{(i_{i})}\n",
            "cropped_1_.jpg  -  J_{(11)T,t}^{(i i_{2})q}=\\frac{1}{2}(T-t)\\left\\lfloor\\zeta_{0}^{(i_{i})}\\zeta_{0}^{(i_{2})}+\\frac{1}{\\pi}\\sum_{r:}^{\\ell}\n",
            "cropped_19_.jpg  -  \\left\\{(J_{(001)T,t}^{(00i_{1})}-J_{(001)T,t}^{(00i_{1})q})^{2}\\right\\}=(\n",
            "cropped_0_.jpg  -  \\xi_{q}^{(i)}=\\frac{1}{\\sqrt{\\Omega_{q}}\\,,}\n",
            "cropped_3_.jpg  -  \\;+{\\frac{\\sqrt{2}}{\\pi}}{\\sqrt{\\Omega_{*}}}\n",
            "cropped_8_.jpg  -  \\begin{array}{c}{{\\displaystyle{}^{-}\\left(\\zeta^{\\left(i_{1}\\right)}\\zeta^{\\left(i_{2}\\right)}\\right.\\right.-\\left.\\zeta^{\\left(i_{1}\\right)}\\zeta^{\\left(i_{2}\\right)}\\right)-\\prod_{\\{i_{1}=i_{2}\\}}\\right)}}\\end{array}\n",
            "cropped_11_.jpg  -  \\begin{array}{l l}{{\\underline{{\\chi}}}\\left({\\hat{I}}}\\\\ {{\\underline{{\\chi}}}}\\\\ {{\\underline{{\\bullet}}}}\\end{array}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "dir_list = os.listdir(\"/content/\") \n",
        "\n",
        "for i in dir_list:\n",
        "  if i.endswith(\".jpg\"):\n",
        "    img_path = \"/content/\" + i\n",
        "    formula = forumla_detection(img_path)\n",
        "    print(i,\" - \",formula)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Display latex in Jupyter Notebook "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Cv4IEgTmdtBW",
        "outputId": "f734950f-cd7b-4084-f61c-2b4d6f689c76"
      },
      "outputs": [
        {
          "data": {
            "text/latex": [
              "{\begin{array}{l l}{{\\mathrm{AABGCCSC}\\mathrm{ABQR~f~AM~are~alindes~of~AABC~and~APQR~respecively~and~AB^{2}:}}}\\ {{\\mathrm{PQ^{2}=4:9,\\qquad(81~4)~16.81~}}}&{{(8)~4;9}}&{{(\\mathrm{(1)~3.7~}}}\\ {{(\\mathrm{(4)~16.51~}}}&{{(81~4)~16.51~}}}&{{(8)~4.9}}\\end{array}}"
            ],
            "text/plain": [
              "<IPython.core.display.Latex object>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Latex\n",
        "\n",
        "Latex(\"{\\begin{array}{l l}{{\\mathrm{AABGCCSC}\\mathrm{ABQR~f~AM~are~alindes~of~AABC~and~APQR~respecively~and~AB^{2}:}}}\\\\ {{\\mathrm{PQ^{2}=4:9,\\qquad(81~4)~16.81~}}}&{{(8)~4;9}}&{{(\\mathrm{(1)~3.7~}}}\\\\ {{(\\mathrm{(4)~16.51~}}}&{{(81~4)~16.51~}}}&{{(8)~4.9}}\\end{array}}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdQpTsYRfa0G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
