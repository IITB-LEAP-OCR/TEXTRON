{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["N50Uyw2va3GX"],"authorship_tag":"ABX9TyMdJH6sxh6eA/djCno79F/f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NywfIRYoaXZh","executionInfo":{"status":"ok","timestamp":1666111325658,"user_tz":-330,"elapsed":31869,"user":{"displayName":"Soham Mistri","userId":"07555918091432069006"}},"outputId":"f6d422a8-40ed-42ca-8ddb-ca6ea962e49c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Paper 1: [UNSUPERVISED IMAGE SEGMENTATION BY BACKPROPAGATION](https://kanezaki.github.io/pytorch-unsupervised-segmentation/ICASSP2018_kanezaki.pdf) (ICAASP 2018)"],"metadata":{"id":"cuaBm72MZeZi"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"ii2bNqZgZbYv","executionInfo":{"status":"ok","timestamp":1666111336301,"user_tz":-330,"elapsed":4554,"user":{"displayName":"Soham Mistri","userId":"07555918091432069006"}}},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","import cv2\n","import sys\n","import numpy as np\n","from skimage import segmentation\n","import torch.nn.init\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","source":["use_cuda = torch.cuda.is_available()\n","use_cuda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3O3Ad-FmaTb6","executionInfo":{"status":"ok","timestamp":1666111340456,"user_tz":-330,"elapsed":1368,"user":{"displayName":"Soham Mistri","userId":"07555918091432069006"}},"outputId":"71b0de4d-aafe-4e25-9095-243f8fd91751"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["CONFIG = {\n","    \"nChannel\":100,\n","    \"maxIter\":1000,\n","    \"minLabels\":50,\n","    \"lr\":0.1,\n","    \"nConv\":2,\n","    \"num_superpixels\":10000,\n","    \"compactness\":10\n","}"],"metadata":{"id":"A-2Dhhcpa_Q2","executionInfo":{"status":"ok","timestamp":1666118379726,"user_tz":-330,"elapsed":2,"user":{"displayName":"Soham Mistri","userId":"07555918091432069006"}}},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":["# CNN Model"],"metadata":{"id":"N50Uyw2va3GX"}},{"cell_type":"code","source":["class MyNet(nn.Module):\n","    def __init__(self,input_dim):\n","        super(MyNet, self).__init__()\n","\n","        ##conv1 and conv2 are the M feature extractors\n","        self.conv1 = nn.Conv2d(input_dim, CONFIG[\"nChannel\"], kernel_size=3, stride=1, padding=1 )\n","        self.bn1 = nn.BatchNorm2d(CONFIG[\"nChannel\"])\n","        self.conv2 = nn.ModuleList()\n","        self.bn2 = nn.ModuleList()\n","        for i in range(CONFIG[\"nConv\"]-1):\n","            self.conv2.append( nn.Conv2d(CONFIG[\"nChannel\"], CONFIG[\"nChannel\"], kernel_size=3, stride=1, padding=1 ) )\n","            self.bn2.append( nn.BatchNorm2d(CONFIG[\"nChannel\"]) )\n","\n","        ## Now the p channels are reduced to q (here p=q so nChannel only)\n","        self.conv3 = nn.Conv2d(CONFIG[\"nChannel\"], CONFIG[\"nChannel\"], kernel_size=1, stride=1, padding=0 )\n","        self.bn3 = nn.BatchNorm2d(CONFIG[\"nChannel\"])\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu( x )\n","        x = self.bn1(x)\n","        for i in range(CONFIG[\"nConv\"]-1):\n","            x = self.conv2[i](x)\n","            x = F.relu( x )\n","            x = self.bn2[i](x)\n","        x = self.conv3(x)\n","        x = self.bn3(x)\n","        return x"],"metadata":{"id":"i1VD4mOYa0S6","executionInfo":{"status":"ok","timestamp":1666111950813,"user_tz":-330,"elapsed":4,"user":{"displayName":"Soham Mistri","userId":"07555918091432069006"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"pDoq21Lkc30p"}},{"cell_type":"code","source":["# train\n","def train(image, l_inds):\n","    model = MyNet(image.size(1))\n","    if use_cuda:\n","        model.cuda()\n","    model.train()\n","    loss_fn = torch.nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=CONFIG[\"lr\"], momentum=0.9)\n","    \n","    for batch_idx in range(CONFIG[\"maxIter\"]):\n","        # forward pass to get the class labels\n","        optimizer.zero_grad()\n","        output = model(image)[ 0 ]\n","        output = output.permute( 1, 2, 0 ).contiguous().view( -1, CONFIG[\"nChannel\"] )  #flattened out for every pixel\n","        \n","        #argmax step\n","        ignore, target = torch.max( output, 1 ) #size is (H*W,1)\n","        im_target = target.data.cpu().numpy()\n","        \n","        # if args.visualize:\n","        #     im_target_rgb = np.array([label_colours[ c % 100 ] for c in im_target])\n","        #     im_target_rgb = im_target_rgb.reshape( im.shape ).astype( np.uint8 )\n","        #     cv2.imshow( \"output\", im_target_rgb )\n","        #     cv2.waitKey(10)\n","\n","\n","        # superpixel refinement\n","        # TODO: use Torch Variable instead of numpy for faster calculation\n","        for i in range(len(l_inds)):\n","            labels_per_sp = im_target[ l_inds[ i ] ]\n","            u_labels_per_sp = np.unique( labels_per_sp )\n","            hist = np.zeros( len(u_labels_per_sp) )\n","            for j in range(len(hist)):\n","                hist[ j ] = len( np.where( labels_per_sp == u_labels_per_sp[ j ] )[ 0 ] )\n","            im_target[ l_inds[ i ] ] = u_labels_per_sp[ np.argmax( hist ) ]\n","\n","        nLabels = len(np.unique(im_target))\n","        target = torch.from_numpy( im_target )\n","        if use_cuda:\n","            target = target.cuda()\n","\n","        if nLabels <= CONFIG[\"minLabels\"]:\n","            print(np.unique(im_target))\n","            print(len(np.unique(im_target)))\n","            print (\"nLabels\", nLabels, \"reached minLabels\", CONFIG[\"minLabels\"], \".\")\n","            classes = np.unique(im_target)\n","            print(classes)\n","            for j in classes:\n","                res = np.array([0 if c==j else 255 for c in im_target])\n","                res_rgb = res.reshape((1000,1000)).astype( np.uint8 )\n","                cv2.imwrite(os.path.join(\"/content/result\",\"{}.png\".format(j)), res_rgb)\n","            break\n","\n","        target = Variable( target )\n","        loss = loss_fn(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        print (batch_idx, '/', CONFIG[\"maxIter\"], ':', nLabels, loss.item())\n","\n","        \n","        #print (batch_idx, '/', args.maxIter, ':', nLabels, loss.data[0])\n","\n","    # model.eval()  \n","    # output = model(data)[ 0 ]\n","    # output = output.permute( 1, 2, 0 ).contiguous().view( -1, CONFIG[\"nChannel\"])\n","    # ignore, target = torch.max( output, 1 )\n","    # im_target = target.data.cpu().numpy()\n","\n","    # classes = np.unique(im_target)\n","    # print(classes)\n","    # for j in classes:\n","    #     res = np.array([0 if c==j else 255 for c in im_target])\n","    #     res_rgb = res.reshape((1000,1000)).astype( np.uint8 )\n","    #     cv2.imwrite(os.path.join(\"/content/result\",\"{}.png\".format(j)), res_rgb)\n","\n","    torch.save(model.state_dict(), \"/content/model.pt\")\n","    \n","    # return model"],"metadata":{"id":"7YuuC3dcc5DB","executionInfo":{"status":"ok","timestamp":1666118391182,"user_tz":-330,"elapsed":489,"user":{"displayName":"Soham Mistri","userId":"07555918091432069006"}}},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":["# Load Image"],"metadata":{"id":"4S6IjaHhg1n-"}},{"cell_type":"code","source":["!rm -rf /content/suppixel\n","!rm -rf /content/result\n","!mkdir /content/suppixel\n","!mkdir /content/result"],"metadata":{"id":"d2sdU4fcIM-z","executionInfo":{"status":"ok","timestamp":1666118401444,"user_tz":-330,"elapsed":855,"user":{"displayName":"Soham Mistri","userId":"07555918091432069006"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["DIR = \"/content/drive/MyDrive/BTP/100Docbank\"\n","l = sorted(os.listdir(DIR))\n","np.random.seed(100)\n","for i in range(1):\n","    idx = np.random.randint(0,len(l))\n","    im = cv2.imread(os.path.join(DIR, l[idx]))\n","    print(im.shape)\n","    im = cv2.resize(im,(1000,1000))\n","    print(im.shape)\n","\n","    # cv2_imshow(im)\n","    data = torch.from_numpy( np.array([im.transpose( (2, 0, 1) ).astype('float32')/255.]) )\n","    if use_cuda:\n","        data = data.cuda()\n","    data = Variable(data)\n","    #data is of form c*h*w\n","\n","    labels = segmentation.slic(im, compactness=CONFIG[\"compactness\"], n_segments=CONFIG[\"num_superpixels\"])\n","    labels = labels.reshape(im.shape[0]*im.shape[1])\n","    u_labels = np.unique(labels)\n","    l_inds = []\n","    for j in range(len(u_labels)):\n","        l_inds.append( np.where( labels == u_labels[ j ] )[ 0 ] )\n","    # print(len(l_inds))\n","    # for j in range(len(l_inds)):\n","    #     supim = np.zeros(labels.shape)\n","    #     for k in l_inds[j]:\n","    #         # print(j)\n","    #         supim[k]=255\n","    #     supim = supim.reshape(im.shape[:2])\n","    #     # print(supim.shape)\n","    #     # print(np.unique(supim))\n","    #     cv2.imwrite(\"/content/suppixel/{}.png\".format(j), supim)\n","    #     # break\n","    train(data, l_inds)\n","\n","    #load model\n","    # model = MyNet(data.size(1))\n","    # model.load_state_dict(torch.load(\"/content/model.pt\")) \n","    # model.eval()\n","    # if use_cuda:\n","    #     model = model.cuda()\n","    # label_colours = np.random.randint(255,size=(100,3))\n","\n","    # im = cv2.imread(os.path.join(DIR, l[idx]))\n","    # print(im.shape)\n","    # im = cv2.resize(im,(1000,1000))\n","    # print(im.shape)\n","\n","    # # cv2_imshow(im)\n","    # data = torch.from_numpy( np.array([im.transpose( (2, 0, 1) ).astype('float32')/255.]) )\n","    # if use_cuda:\n","    #     data = data.cuda()\n","    # data = Variable(data)\n","\n","    # output = model(data)[ 0 ]\n","    # output = output.permute( 1, 2, 0 ).contiguous().view( -1, CONFIG[\"nChannel\"])\n","    # ignore, target = torch.max( output, 1 )\n","    # im_target = target.data.cpu().numpy()\n","\n","    # classes = np.unique(im_target)\n","    # print(classes)\n","    # for j in classes:\n","    #     res = np.array([0 if c==j else 255 for c in im_target])\n","    #     res_rgb = res.reshape((1000,1000)).astype( np.uint8 )\n","    #     cv2.imwrite(os.path.join(\"/content/result\",\"{}.png\".format(j)), res_rgb)\n","    #     # break\n","    # # im_target_rgb = np.array([label_colours[ c % 100 ] for c in im_target])\n","    # # im_target_rgb = im_target_rgb.reshape( im.shape ).astype( np.uint8 )\n","\n","    # # cv2_imshow(im_target_rgb)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IxGi3rmJgwOt","executionInfo":{"status":"ok","timestamp":1666118416870,"user_tz":-330,"elapsed":12241,"user":{"displayName":"Soham Mistri","userId":"07555918091432069006"}},"outputId":"a2efde62-42e3-427e-bf6b-f98d9ad8b90c"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["(2339, 1654, 3)\n","(1000, 1000, 3)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n"]},{"output_type":"stream","name":"stdout","text":["[ 0  2  3  6  7  8 11 12 13 16 25 32 38 39 40 47 50 51 54 58 60 65 68 71\n"," 76 79 86 90 91 92 93]\n","31\n","nLabels 31 reached minLabels 50 .\n","[ 0  2  3  6  7  8 11 12 13 16 25 32 38 39 40 47 50 51 54 58 60 65 68 71\n"," 76 79 86 90 91 92 93]\n"]}]},{"cell_type":"code","source":["!ls /content/suppixel"],"metadata":{"id":"CAr1oU7X_uol","executionInfo":{"status":"ok","timestamp":1666114787179,"user_tz":-330,"elapsed":469,"user":{"displayName":"Soham Mistri","userId":"07555918091432069006"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nYWuIyOX_VMl"},"execution_count":null,"outputs":[]}]}